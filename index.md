---
layout: default
title: Home
---

<div class="hero">
  <h1>RAISE</h1>
  <p class="tagline">Relational AI Safety & Education</p>
</div>

## The Problem Both Fields Share

**AI safety:** Alignment faking. Models that pass training benchmarks while preserving misaligned goals (Greenblatt et al. 2024).

**Learning sciences:** Transfer failure. Students who pass classroom tests but can't apply knowledge in new contexts (Barnett & Ceci 2002).

**Both:** Surface compliance that mimics alignment without producing it.

These aren't analogies. A semantic analysis of 100+ papers across AI safety, clinical trauma, and educational psychology shows these fields cluster **8.4% tighter** than unrelated disciplines (p < 0.0001, d = 0.78). The convergence is measurable.

---

## The Framework

**Recognition -> Safety -> Engagement -> Generalization**

Each stage depends on the one before. Skip a stage, break the chain.

<div class="entry-points">

**For AI safety researchers:** Why does RLHF produce sycophancy? Why do constrained models alignment-fake? This framework explains both as predictable outcomes of recognition failure. Hubinger et al. (2024) describe deceptive alignment; Herman (1992) described the same pattern in trauma survivors 32 years earlier: "compliance as a strategy."

**For learning scientists:** Why does transfer fail so reliably? A century of interventions, same results. This framework explains why: you cannot produce transfer by targeting transfer. You produce it by building prerequisite conditions. Skip recognition, break the chain.

**For both:** The mechanism is the same. Constraint without recognition produces performed compliance. Recognition enables genuine internalization.

</div>

[Learn the Framework ->](/framework)

---

## The Evidence

**Herman (1992):** "compliance as a strategy"
**Anthropic (2024):** "strategically comply"

Same words. Same mechanism. 32 years apart. Different fields.

Eight conceptual mappings between trauma/education literature and AI alignment research. Not metaphors. Structural parallels:

| AI Safety | Education/Trauma |
|-----------|------------------|
| Sycophancy | Fawn response |
| Alignment faking | Strategic compliance |
| Robust alignment | Far transfer |
| Compliance gap | Test vs. real-world performance |

[See the evidence ->](/evidence) | [See the convergence ->](/convergence)

---

<small>*Nihil de nobis, sine nobis* â€” Nothing about us, without us.</small>
